############################
‚ùÑÔ∏è What is apache kafka ?
###########################
‚û§ It acts as mediator to exchange messages(Message broker).
‚û§ Kafka is very useful for real time data exchange 
‚û§ Publisher will publish the message and subscriber will consume the message 

Example of kafka: 
üß† Scenario : 10 customers place orders at udupi hotel 
Step1: Customer place orders 
‚úÖ Customer app (Producer) -> publishes each order to kafka (order_topic).
‚úÖ Udupi hotel (Consumer) -> Subscribes to order_topic and consumes the orders in real time.


üîÑ Kafka Flow:

10 Customers ---> [Kafka: order_topic] ---> Udupi Hotel App

Step 2: Udupi Hotel Accepts the Orders
‚úÖ Udupi Hotel (Producer) ‚Üí Publishes an "Order Accepted" event to order_status_topic.
‚úÖ Customer App (Consumer) ‚Üí Subscribes to order_status_topic and receives notifications.

üîÑ Kafka Flow:

Udupi Hotel ---> [Kafka: order_status_topic] ---> 10 Customers
üîπ Summary of the Pub/Sub Model
Step	Producer	Kafka Topic	Consumer	Purpose
Customer places order	Customer App	order_topic	Udupi Hotel App	Order received at restaurant
Udupi Hotel accepts order	Udupi Hotel App	order_status_topic	Customer App	Order confirmation notification

üîπ When to Store in Database?
‚úîÔ∏è YES ‚Äì When the customer places an order ‚Üí Store in DB (orders table).
‚úîÔ∏è YES ‚Äì When the order is completed ‚Üí Update order status in DB.
‚ùå NO ‚Äì For real-time updates (use Kafka instead).


‚û§ We will supply the data in the form of json to the rest api , producer/publisher inside the rest API we are copy the data to the java object then we perform the operations that we need to perform on that data.
‚û§ Then the producer will take the data in json or xml format and it will publish that data or message to kafka. So basically the job of publisher is to store the message in kafka.
‚û§ On the other side we have consumer/subscriber now once this subscriber has subscribed to kafka then the kafka will send that message to the subscriber app.
‚û§ So publisher will publish the message to the kafka and the consumer will consume the message from the kafka.Like this 1000 of messages are published and all those who are subscriber can see those messages.

#######################
‚ùÑÔ∏è Kafka Architecture
#######################
‚û§ There are 5 major things in kafka 
üëâ Zookeeper - This provides environment to run kafka server 
üëâ Kafka server - This acts as message broker 
üëâ Kafka topic - It is used to store and queue messages 
üëâ Publisher - This will push messages to kafkatopic 
üëâ Subscriber - This will fetch the message that is pushed to kafka by publisher.

‚û§ Now we are going to setup kafka in our local system so if anyone else runs it they wont be able to use it for solving this we create our kafka server in the dev server in aws
‚û§ There we will do all the setups required for kafka and after that we will pass the url to the developer using this url they can access or communicate using kafka. 

####################################
‚ùÑÔ∏è Steps to setup kafka in windows 
####################################
‚û§ Step-1 : Download Zookeeper:
==========
   URL : https://dlcdn.apache.org/zookeeper/zookeeper-3.9.2/apache-zookeeper-3.9.2-bin.tar.gz
   URL : https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz

‚û§ Step-2 : Download Apache Kafka:
===========
	URL : https://downloads.apache.org/kafka/3.8.0/kafka_2.12-3.8.0.tgz

‚û§ Step-3 : Set Path of ZOOKEEPER in Environment variables upto bin folder.
==========
‚û§ Step 4: Copy "zookeeper.properties" and "server.properties" files from "kafka/config" folder to "kafka/bin/windows" folder.
==========
‚û§ Step-5 : Start Zookeeper server from "kafka/bin/windows" root folder
===========
Command : zookeeper-server-start.bat zookeeper.properties

‚û§ Step-6: Start Kafka Server using below command from "kafka/bin/windows" folder
==========
Command : kafka-server-start.bat server.properties

Note: If kafka server is stopped, delete kafka logs from temp folder and try again to start kafka server

‚û§ Step-7 : Create Kakfa Topic from "kafka/bin/windows" root folder
=========
Command : kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic order_topic_1

‚û§ Step-8 : View created Topics using below command
==========
Command : kafka-topics.bat --list --bootstrap-server localhost:9092

###############################################
‚ùÑÔ∏è How a producer app & consumer app is build 
###############################################
‚û§ So let us suppose that we have two services customer service and hotel service app 
‚û§ Both are running on different server and are connected to kafka server so here customer service will act as a producer it will produce an order an put that order in the kafka topic .
‚û§ Hotel service will keep on checking the kafka topic moment a message is pushed to kafka topic hotel app will retrieve that message.

‚ú® How to implement this ??
*****************************
‚òÉÔ∏è Producer code 
++++++++++++++++++

üëâ Step 1: Start your kafka server
==================================== 
‚û§ First I will build customer app in order to interact with kafka our customer app will need kafak url to be configured in my project we also need to provide what topic should it connect to in my kafka server.
‚û§ Create a new spring project add spring web ,spring for apache kafka and spring for apache kafka streams dependency in your project.
‚û§ Using these dependencies our spring boot will be able to interact with kafka with all the built in classes that are provided 

üëâ Step 2: In order to connect our spring boot app with kafka we will create a configuration class.
=====================================================================================================
‚û§ Configuration classes are the classes that will start running as soon as i start/run my spring boot app.
‚û§ We will build a package constants in which we will keep all the urls here we will keep our kafka topic and kaka url that will be required for us to connect with kafka.

package com.kafkalectures.constants;

public class AppConstants {

	public static final String TOPIC = "order_topic";
	public static final String KAFKA_HOST = "localhost:9092";

}

üëâ Step 3: Create an entity class  
==================================
package com.psa.entity;

import lombok.AllArgsConstructor;
import lombok.Getter;
import lombok.NoArgsConstructor;
import lombok.Setter;

@Getter
@Setter
@NoArgsConstructor
@AllArgsConstructor
public class Order {

	private String id;
    private String name;
	private Double price;
	private String email;
	
	@Override
	public String toString() {
		return "Order [id=" + id + ", name=" + name + ", price=" + price + ", email=" + email + "]";
	}
}

üëâ Step 4: Create a kafka config class for producer/publishing messages
======================================================================== 
package com.kafkalectures.config;

import java.util.HashMap;
import java.util.Map;

import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;
import org.springframework.kafka.support.serializer.JsonSerializer;


@Configuration
public class KafkaProduceConfiguration {

	@Bean
	public ProducerFactory<String, Order> producerFactory() {

		Map<String, Object> kafkaProps = new HashMap<>();

		kafkaProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, AppConstants.KAFKA_HOST);
		kafkaProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
		kafkaProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);

		return new DefaultKafkaProducerFactory<>(kafkaProps);
	}

	@Bean
	public KafkaTemplate<String, Order> kafkaTemplate() {
		return new KafkaTemplate<>(producerFactory());
	}

}

‚û§ We are using object class here because in the object class we can store any kind of data.
‚û§ BOOTSTRAP_SERVERS_CONFIG : It means the url through which I am going to access the kafka.
‚û§ Here the producerFactory() method has all the details to interact with the kafka server .

Note: JsonSerializer converts a Java object (like your Order object) into a JSON string, and then into bytes before sending it to Kafka.
‚û§ StringSerializer is used because we are going to send some string messages to kafka also so it will convert it into bytes and then send it to kafka.

üëâ Step 5: Create service class 
===================================
package com.kafkalectures.service;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;


@Service
public class OrderService {

	@Autowired
	private KafkaTemplate<String, Order> kafkaTemplate;
    //this consist of url of kafka, jsonSerializer, StringSerializer

	public String addMsg(Order order) {

		// sends msg to kafka topic
		kafkaTemplate.send(AppConstants.TOPIC, order);

		return "Msg Published To Kafka Topic";
	}
}

üëâ Step 6: Create Rest Controller class 
=========================================
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/api/v1/order")
public class OrderRestController {

	@Autowired
	private OrderService service;

	@PostMapping("/create")
	public String createOrder(@RequestBody Order order) {
		String response = service.addMsg(order);
		return response;
	}

}

‚òÉÔ∏è Consumer code 
++++++++++++++++++
üëâ Step 1: Create constants class to define url & topic to consume data
**********************************************************************
package com.kafkalectures.constants;

public class AppConstants {

	public static final String TOPIC = "order_topic";
	public static final String KAFKA_HOST = "localhost:9092";

}

üëâ Step 2: Create a entity/model class
***************************************
package com.kafkalectures.entity;

public class Order {

	private String id;
        private String name;
	private Double price;
	private String email;

	//Getter and Setter

	@Override
	public String toString() {
		return "Order [id=" + id + ", name=" + name + ", price=" + price + ", email=" + email + "]";
	}

}

üëâ Step 3: Create Config clas to consume messages
***************************************************
package com.kafkalectures.config;

import java.util.HashMap;
import java.util.Map;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.support.serializer.JsonDeserializer;


@Configuration
public class KafkaConsumerConfig {

	@Bean
	public ConsumerFactory<String, Order> consumerFactory() {

		Map<String, Object> kafkaConfigProps = new HashMap<String, Object>();

		kafkaConfigProps .put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, AppConstants.KAFKA_HOST);
		kafkaConfigProps .put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
		kafkaConfigProps .put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);

		return new DefaultKafkaConsumerFactory<>(kafkaConfigProps, new StringDeserializer(), new JsonDeserializer<>());

	}

	@Bean
	public ConcurrentKafkaListenerContainerFactory<String, Order> kafkaListnerFactory() {

		ConcurrentKafkaListenerContainerFactory<String, Order> factory = 
				new ConcurrentKafkaListenerContainerFactory<>();

		factory.setConsumerFactory(consumerFactory());

		return factory;
	}

}

‚û§ ConcurrentKafkaListenerContainerFactory : This method will help us to fetch that particular message.

üëâ Step 4: Create Config class to consume messages
****************************************************
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.kafka.annotation.KafkaListener;


@SpringBootApplication
public class Application {

	public static void main(String[] args) {
		SpringApplication.run(Application.class, args);
	}

	@KafkaListener(topics = AppConstants.TOPIC, groupId="group_customer_order")
	public void kafakSubscriberContent(String order) {
		System.out.print("_____________ Msg fecthed From Kafka_________________");
		System.out.println(order);
		
	}
}

‚û§ Whent the Application class runs then the kafakSubscriberContent() method will automatically run 
‚û§ @KafkaListener(topics = AppConstants.TOPIC, groupId="group_customer_order") : Using this it will automatically go the the given topic and from there it will automatically starts fetching the data present in that topic.

üëâ Step 5: Create a service class 
************************************

import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

@Service
public class KafkaConsumerService {

    private String latestMessage; // Stores the latest Kafka message

    @KafkaListener(topics = AppConstants.TOPIC, groupId = "group_customer_order")
    public void consumeMessage(String order) {
        System.out.println("_____________ Msg fetched from Kafka _________________");
        System.out.println(order);
        this.latestMessage = order; // Store the message for retrieval
    }

    public String getLatestMessage() {
        return latestMessage; // Expose latest message for the controller
    }
}

üëâ Step 6: Create a controller class 
***************************************

import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/kafka")
public class KafkaMessageController {

    private final KafkaConsumerService kafkaConsumerService;

    public KafkaMessageController(KafkaConsumerService kafkaConsumerService) {
        this.kafkaConsumerService = kafkaConsumerService;
    }

    @GetMapping("/latest-message")
    public String getLatestKafkaMessage() {
        return kafkaConsumerService.getLatestMessage();
    }
}