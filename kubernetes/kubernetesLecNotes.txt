######################
â„ï¸ What is Docker ?
#####################
âž¤ Docker is a free and open-source containerization software that allows you to package applications along with their dependencies into a single unit called a Docker Image. This image can run on any system that has Docker installed, making deployment easy and consistent across different environments.

ðŸŒŸ Why use Docker?
*******************
âœ… Portability â€“ Run the same application on any machine, regardless of OS configuration.
âœ… Dependency Management â€“ Ensures that all required software (e.g., libraries, databases, and runtimes) is included within the image.
âœ… Fast Deployment â€“ No need to manually install dependencies every time you set up a new environment.
âœ… Resource Efficiency â€“ Uses fewer resources compared to traditional virtual machines.

######################
â„ï¸ How Docker Works?
######################
âž¤ Create a Docker Image â€“ Package the app code + dependencies into a lightweight container image.
âž¤ Run the Docker Container â€“ Deploy this image as a container using the docker run command.
âž¤ Execute Anywhere â€“ The same image runs on any machine with Docker installed.
âž¤ Once the image is built, it can run on any machine without requiring additional software setup.

#########################
â„ï¸ What is kubernetes ?
#########################
âž¤ Kubernetes (K8s) is a free and open source orchestration(management) tool developed by google to manage containerized applications. 
âž¤ orchestration = managing multiple containers efficiently.

âž¤ Kubernetes automates key tasks like: 
1. Creating , Starting and stopping containers 
2. Scaling up/down based on demand 
3. Handling failures automatically. 

#########################
â„ï¸ Why use kubernetes ? 
#########################
âœ… Orchestration â€“ Efficiently manages multiple containers across a cluster of machines.
âœ… Self-Healing â€“ If a container crashes, Kubernetes automatically replaces it.
âœ… Load Balancing â€“ Distributes traffic across multiple containers to avoid overloading.
âœ… Auto Scaling â€“ Increases or decreases the number of running containers based on traffic load.
âœ… Automated Deployments â€“ Supports CI/CD for rolling updates and version control.

ðŸŒŸ Kubernetes Advantages 
*************************
1. Orchestration : Managing containers 
---------------------------------------
âž¤ Kubernetes helps manage multiple docker containers across different machines (nodes) efficiently 
âž¤ Instead of running docker run manually for each container, kubernetes automates deployment 
âž¤ It ensures that all containers are running smoothly and adjusts their status as needed.

ðŸ‘‰ Note: Kubernetes ensures all these containers are running ,Healthy , and adjusts their status as needed.

2. Self healing : Automatic recovery 
--------------------------------------
âž¤ If a container crashes due to an error or system failure ,Kubernetes automatically restarts a new instance.
Ex: A web server container(Apache, Nginx) stops unexpectedly.
âž¤ Kubernetes detects the failure and starts a new container to replace it.
âž¤ Users never notice downtime.

3. Load Balancing â€“ Distributes Traffic Efficiently
---------------------------------------------------
âž¤ Kubernetes distributes incoming user requests across multiple containers to avoid overloading any single instance.

ðŸ“Œ Example:
------------
A shopping website experiences high traffic during a sale.

âž¤ Kubernetes ensures that requests are evenly distributed across available backend servers.
âž¤ Prevents server crashes and ensures smooth performance.

4. Auto Scaling â€“ Adjusting Resources Dynamically
--------------------------------------------------
âž¤ Kubernetes can increase or decrease the number of containers automatically based on traffic load.

ðŸ“Œ Example:
âž¤ If website traffic increases, Kubernetes adds more containers to handle the load.
âž¤ If traffic reduces, Kubernetes removes extra containers to save resources.
âž¤ Works similarly to cloud-based Auto Scaling Groups (ASG).

âž¤ Conclusion
================
ðŸš€ Docker simplifies packaging applications into portable containers.
ðŸš€ Kubernetes ensures these containers are orchestrated, scalable, and reliable.

ðŸ‘‰ Together, Docker & Kubernetes enable modern cloud-native application deploymentâ€”making applications highly available, efficient, and automated.

########################################################
â„ï¸ Kubernetes (K8s) Architecture - Explained in Detail
#########################################################
1) Control Plane (Master Node/Control Node)
**********************************************
-> The control plane is responsible for managing the Kubernetes cluster. It includes the following components:

1. API Server: Receives requests from kubectl and manages cluster operations.

2. Scheduler: Identifies pending tasks in ETCD and assigns them to worker nodes.

3. Controller Manager: Ensures the clusterâ€™s desired state matches the actual state.

4. ETCD: A distributed key-value store that acts as Kubernetes' internal database.

2) Worker Nodes (Slave Nodes)
******************************
-> Worker nodes run application workloads. They include the following components:

1. Kubelet: A node agent that communicates with the control plane and manages containers.

2. Kube Proxy: Manages networking and ensures communication within the cluster.

3. Docker Engine: Runs and manages containerized applications.

4. Pod: The smallest deployable unit in Kubernetes, housing one or more containers.

5. Container: Runs inside a Pod and contains the application code.

#####################################
ðŸš€ What is a POD in Kubernetes?
#####################################

âœ… Key Concepts Explained:
-----------------------------
1. If you deploy an app, it will ultimately run inside one or more Pods. It is a building block to run app that we deploy in K8S

2. "Applications will be deployed as PODS in k8s."
Your app (e.g., a Spring Boot API) will be containerized using Docker. This container will then be wrapped inside a Pod and deployed on the cluster.

3. "To create PODS we will use Docker images."
A Pod runs one or more containers (usually one), and each container uses a Docker image. You can build a Docker image of your app and then deploy it inside a Pod.

4. "To create PODS we will use Manifest YML file."
A YAML manifest file defines the configuration for the Pod (or other resources like Deployments).

It includes:

a. The name of the Pod

b. The image to use

c. Ports to expose

c. Environment variables, etc.


5. "Create multiple PODS."
The same image (e.g., myapp:latest) can be used to create many Pods. This is how you scale your applicationâ€”running multiple copies (Pods) to handle more traffic.

6. "If we run application with multiple pods then Load Balancing can be performed resulting in 99.9% uptime of the application."
High Availability: If one Pod crashes, others are still running, so your app stays available.Load Balancing: Kubernetes distributes traffic across Pods using a Service (like a load balancer).

7. "PODS count will be increased and decreased based on the demand (scalability)."
Kubernetes supports auto-scaling. You can scale Pods manually or automatically using a Horizontal Pod Autoscaler (HPA). Based on CPU/memory usage or custom metrics, Kubernetes will increase/decrease the number of Pods.


###############################
ðŸš€ Kubernetes Services
###############################

-> A Kubernetes Service is used to expose a group of Pods so that they can be accessed reliably. Since Pods can be created and destroyed at any time (with changing IPs), a Service gives them a stable network identity.

---------------------------
ðŸ§­ Why Do We Use Services?
---------------------------

-> Pods are short-lived and can crash or restart.

-> Each time a Pod is created, it gets a new IP address.

-> Directly accessing Pods via IP is not reliable.

-> A Service gives a static IP to a group of Pods.

---------------------------------
ðŸŒ Types of Kubernetes Services
---------------------------------

Kubernetes offers different types of services depending on how and where you want to expose your Pods:

ðŸ”¹ 1. ClusterIP (Default)
ðŸ”¸ 2. NodePort
ðŸ”¹ 3. LoadBalancer

-------------------------------------------------------
ðŸ” ClusterIP Service (Internal Access Only)
-------------------------------------------------------

ðŸ“Œ Key Points:
-> Pods are short-lived objects; if one crashes, Kubernetes replaces it with a new Pod.
-> Every new Pod gets a different IP address.

Note: ðŸ›‘ Never rely on Pod IPs to access an application.

-> A ClusterIP Service groups multiple Pods  and assigns them a single static IP.

-> This static IP allows other components inside the cluster to access the group of Pods reliably, even when individual Pods change.

---------------------
ðŸš« Access Scope:
---------------------

-> Only accessible within the Kubernetes cluster.

-> Not reachable from the outside world (internet or external clients).

----------------
ðŸ’¡ Use Case:
----------------
-> Internal services such as databases, backend APIs, authentication services, etc.

Example: You donâ€™t want to expose a database Pod to the internet, so you use a ClusterIP service to allow access only from other internal Pods.

----------------------------------------------------
ðŸŒ What is a NodePort Service in Kubernetes?
----------------------------------------------------
-> A NodePort service is a type of Kubernetes Service that exposes your Pods outside the cluster using a port on each worker node (called a "NodePort").

ðŸ§­ Why Use NodePort?
------------------------------------
By default, Pods and ClusterIP services are only accessible within the cluster.

NodePort makes them accessible externally by opening a static port (from 30000 to 32767) on each worker node.

It allows you to access your application using:

http://<NodeIP>:<NodePort>


Note: Here all traffic is routed to one worker node. Means load balancing cannot happen here.
