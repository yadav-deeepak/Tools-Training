###############################
ğŸŒ What is Kubernetes (K8s)?
###############################
â¤ Kubernetes is an open-source container orchestration platform
ğŸ‘‰ It helps you manage, deploy, scale, update, and heal containerized applications automatically.

â¤ Created by Google, now maintained by CNCF (Cloud Native Computing Foundation).
â¤ Think of Kubernetes as a â€œmanagerâ€ for your Docker containers â€” it organizes everything so apps run smoothly at scale.

ğŸš€ Why Do We Use Kubernetes? (Purpose & Benefits)
**************************************************
â­ 1. Automatic Scaling
=========================
â¤ Kubernetes automatically increases or decreases the number of containers based on load.
ğŸ‘‰ Example: If your app gets heavy traffic, K8s adds more containers automatically.

â­ 2. Self-Healing (Auto Recovery)
=====================================
â¤ If a container crashes, K8s restarts it automatically.
â¤ If a node fails, K8s shifts workloads to healthy nodes.

ğŸ‘‰ This ensures your application never goes down.

â­ 3. Load Balancing
=======================
â¤ K8s distributes traffic evenly to all healthy pods.
ğŸ‘‰ No server overload problems.

â­ 4. Easy Deployment & Rollback
==================================
â¤ Kubernetes allows:
â¤ Rolling updates
â¤ Zero downtime deployments
â¤ Easy rollback to previous version if something breaks

â­ 5. Infrastructure Abstraction
==================================
â¤ You donâ€™t need to worry about underlying servers.
ğŸ‘‰ Kubernetes decides where to run your containers.

â­ 6. High Availability
=========================
â¤ Kubernetes ensures your application stays up 24/7 with multiple replicas.

â­ 7. Resource Optimization
============================
â¤ K8s uses CPU & RAM efficiently by placing containers smartly across nodes.

â­ 8. Portable Across Clouds
=============================
â¤ Kubernetes runs everywhere:
â¤ AWS
â¤ Azure
â¤ GCP
â¤ On-premise
â¤ Local (Minikube / Kind)

ğŸ‘‰ No vendor lock-in.

ğŸ¯ In One Line
*****************
â¤ Kubernetes = A powerful platform to run, manage, scale, heal, update, and operate containers automatically at any scale.

###########################################################
ğŸ—ï¸â˜¸ï¸ Kubernetes Architecture (Masterâ€“Worker Architecture)
###########################################################
â¤ Kubernetes follows a Masterâ€“Worker (Control Plane â€“ Node) architecture, where the Control Plane manages the cluster, and Worker Nodes run your applications inside Pods.
â¤ Letâ€™s break it down clearly for your notes ğŸ‘‡

ğŸ§  1. Control Plane Components (Master Node)
***********************************************
â¤ The brain of Kubernetes â€” responsible for managing the entire cluster.

ğŸ“ ğŸ§­ API Server (kube-apiserver)
====================================
â¤ Acts as the front door of the Kubernetes cluster.
â¤ All commands (kubectl / other components) go through the API Server.
â¤ It validates requests and updates the cluster state.

ğŸ‘‰ Think of it as the â€œReception Deskâ€ of Kubernetes.

ğŸ§± ğŸ“š etcd (Key-Value Store)
===============================
â¤ A distributed, consistent key-value database.
â¤ Stores entire cluster state:
â¤ Pods
â¤ Nodes
â¤ Configs
â¤ Secrets
â¤ If etcd fails, Kubernetes breaks.

ğŸ‘‰ Itâ€™s the â€œmemoryâ€ of the cluster.

ğŸ§  ğŸ“¡ Controller Manager (kube-controller-manager)
===================================================
â¤ Ensures the actual state matches the desired state.
â¤ Runs multiple controllers:
â¤ Node Controller
â¤ Deployment Controller
â¤ ReplicaSet Controller
â¤ Job Controller

ğŸ‘‰ Itâ€™s the â€œautomation brainâ€ that keeps everything correct.

ğŸ—ºï¸ âš–ï¸ Scheduler (kube-scheduler)
===================================
â¤ Decides on which node a Pod should run.
â¤ Scheduler checks:
â¤ Available CPU
â¤ Available RAM
â¤ Node health
â¤ Taints/Tolerations

ğŸ‘‰ Itâ€™s the â€œPlacement Officerâ€ of the cluster.

ğŸ–¥ï¸ 2. Worker Node Components
******************************
Nodes where your applications actually run inside Pods.

ğŸ“¦ ğŸš€ Kubelet
================
â¤ Agent running on every node.
â¤ Ensures containers inside Pods are running correctly.
â¤ Communicates with API Server.

ğŸ‘‰ Itâ€™s the â€œEmployeeâ€ who follows the Control Planeâ€™s instructions.

ğŸ“¦ ğŸŒ Kube-Proxy
====================
â¤ Handles networking for Pods.
â¤ Manages:
â¤ Service discovery
â¤ Load balancing
â¤ Ensures traffic reaches the correct Pod.

ğŸ‘‰ Itâ€™s the â€œNetwork Managerâ€ of each node.

ğŸ³ Container Runtime

â¤ Kubernetes uses container engines such as:
â¤ Docker
â¤ containerd
â¤ CRI-O

â¤ Responsible for running actual containers.

ğŸ‘‰ Itâ€™s the â€œMachineâ€ that runs your containers.

ğŸ§© 3. Kubernetes Objects (Run on Worker Nodes)
************************************************
ğŸ§± Pods
==========
â¤ Smallest deployable unit in Kubernetes.
â¤ Contains 1 or more containers.

ğŸŒ Services
============
â¤ Provide stable networking to Pods.

ğŸ—ï¸ Deployments
=================
â¤ Control how Pods are created, updated, or scaled.

ğŸ”„ Flow Of Kubernetes Architecture (Simplified)
*************************************************
1ï¸âƒ£ You give a command:
kubectl apply -f deployment.yaml

2ï¸âƒ£ API Server receives the request.
3ï¸âƒ£ Scheduler decides on which worker node to place Pods.
4ï¸âƒ£ Kubelet runs the Pods on the chosen node.
5ï¸âƒ£ Kube-Proxy manages network traffic.
6ï¸âƒ£ Controller Manager ensures desired state stays maintained.
7ï¸âƒ£ etcd stores all changes permanently.

ğŸ¯ In One Line
******************
â¤ Kubernetes Architecture = Control Plane (brains) + Worker Nodes (execution) working together to run and manage containerized applications automatically.

########################################################
âš™ï¸â˜¸ï¸ How Kubernetes Works (Step-by-Step Explanation)
########################################################
â¤ This is one of the most important topics â€” hereâ€™s the cleanest, note-perfect explanation with stickers and â¤ points.

ğŸš€ 1. Everything Starts With the Desired State
************************************************
â¤ Kubernetes works on the concept of Desired State vs Actual State.
â¤ You tell Kubernetes â€œwhat you want,â€ not â€œhow to do it,â€ using:
â¤ YAML files
â¤ kubectl commands

ğŸ‘‰ Example:
â€œI want 3 replicas of my appâ€ â€” Kubernetes ensures it always keeps 3 running.

ğŸ§¾ 2. You Submit a Request (kubectl or YAML)
**********************************************
â¤ You create a deployment, pod, service, etc.
â¤ Command hits the API Server first.

ğŸ‘‰ API Server = Front desk / Gateway of the cluster

ğŸ’¾ 3. API Server Stores Data in etcd
*************************************
â¤ API Server validates your request.
â¤ Stores the desired state (spec) in etcd, the clusterâ€™s database.

ğŸ‘‰ etcd = â€œMemoryâ€ of Kubernetes

ğŸ§  4. Controller Manager Starts Watching
********************************************
â¤ Controllers continuously watch etcd state.
â¤ They compare:
â¤ Current state
â¤ Desired state

â¤ If something is missing, a controller creates work.
ğŸ‘‰ Example: If only 2 Pods are running but desired is 3 â†’ It creates 1 more.

ğŸ—ºï¸ 5. Scheduler Chooses the Best Node
****************************************
â¤ When a new Pod needs to run, scheduler decides:
â¤ Which node has enough CPU/RAM?
â¤ Is the node healthy?
â¤ Any taints or tolerations?
â¤ Pod affinity/anti-affinity?

ğŸ‘‰ Scheduler = The "Placement Officer"

ğŸ–¥ï¸ 6. Kubelet Executes Pod on Worker Node
******************************************
â¤ Kubelet receives instructions from the control plane.
â¤ It works with the container runtime (Docker / containerd) to start containers.
â¤ Reports back the status (Running/Failed/etc).

ğŸ‘‰ Kubelet = â€œWorker who actually starts the containersâ€

ğŸŒ 7. Kube-Proxy Manages Networking
*************************************
â¤ Exposes Pods using Services.
â¤ Does:
â¤ Load balancing
â¤ Routing
â¤ IP tables / IPVS rules

ğŸ‘‰ Ensures traffic reaches correct Pod.

ğŸ”„ 8. Kubernetes Continuously Monitors Everything (Self-Healing)
*******************************************************************
â¤ If a Pod crashes â†’ Kubernetes restarts it
â¤ If a Node fails â†’ Kubernetes reschedules Pods on another node
â¤ If Pods are unhealthy â†’ Replacements are created
â¤ If container image is updated â†’ Rolling updates happen

ğŸ‘‰ This is what makes Kubernetes powerful and reliable.

ğŸ“ˆ 9. Kubernetes Continuously Maintains Desired State
********************************************************
â¤ It always checks whether what is running = what you asked for.
â¤ If not, controllers fix it automatically.

ğŸ‘‰ Kubernetes is a continuous loop of: Watch â†’ Compare â†’ Act.

ğŸ” 10. High-Level Summary in 5 Steps
**************************************
â¤ You Define the desired state â†’ Deployment.yaml
â¤ API Server Accepts and saves it in etcd
â¤ Controllers Detect missing pods
â¤ Scheduler Assigns pods to nodes
â¤ Kubelet Runs & Maintains the containers

ğŸ¯ In One Line
****************
â¤ Kubernetes works by always trying to match actual state to the desired state using controllers, scheduler, kubelet, and etcd â€” making your applications scalable, self-healing, and automated.

####################################
ğŸ“¦â˜¸ï¸ What is a Pod in Kubernetes?
####################################
â¤ A Pod is the smallest deployable unit in Kubernetes.
â¤ It is a wrapper around one or more containers.
â¤ It runs your application container (like NGINX, Node.js, Java, MySQL, etc).
â¤ Every Pod gets its own:
â¤ IP address
â¤ Storage (if attached)
â¤ Network namespace

ğŸ‘‰ You cannot deploy a container directly in Kubernetes.
You must deploy a POD.

ğŸ”¥ Why Do We Use Pods?
************************
â¤ 1. To run containers
========================
ğŸ‘‰ Containers cannot run directly; Pod is the execution unit.

â¤ 2. To group tightly coupled containers
===========================================
Example:
ğŸ‘‰ App container + Log exporter container
(Both must always run together â†’ they share the same Pod)

â¤ 3. Unique network per Pod
=============================
ğŸ‘‰ Each Pod gets its own IP.
ğŸ‘‰ All containers inside the same Pod share that IP.

â¤ 4. Self-healing with ReplicaSet/Deployment
==============================================
ğŸ‘‰ If a Pod crashes, Kubernetes automatically creates a new one.

ğŸ§  Key Characteristics of Pods
********************************
â¤ Pods are ephemeral
======================
ğŸ‘‰ They are temporary â€” they die and get recreated.

â¤ Pods donâ€™t self-restart
============================
ğŸ‘‰ Instead, ReplicaSet / Deployment ensures replacement.

â¤ One Pod = One App instance
==============================
ğŸ‘‰ If you scale 3 replicas â†’ you get 3 Pods.

â¤ Pods share resources
========================
Containers inside a Pod share:
ğŸ‘‰ Same network
ğŸ‘‰ Same volumes
ğŸ‘‰ Same localhost
ğŸ‘‰ Same IPC namespace

ğŸ“ Example Pod YAML (simple)
*******************************
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: nginx-container
    image: nginx

ğŸ¯ In One Line
****************
â¤ Pod = Smallest unit in Kubernetes that runs one or more containers with a shared network, storage, and lifecycle.

#####################################
ğŸ”Œ What is a Service in Kubernetes?
#####################################
â¤ A Service is a stable networking endpoint that exposes one or more Pods.
â¤ It provides:
â¤ Stable IP address
â¤ Stable DNS name
â¤ Load balancing across Pods
â¤ Internal or external access

ğŸ‘‰ Even if Pods die and new ones are created, the Service IP never changes.

â­ Why Do We Use a Service?
*****************************
â¤ 1. Pods get new IP after restart
====================================
ğŸ‘‰ Service gives a permanent IP for accessing Pods.

â¤ 2. Load balances traffic across multiple Pods
==================================================
ğŸ‘‰ If Deployment has 3 replicas â†’ Service distributes traffic to all.

â¤ 3. Allows communication between microservices
==================================================
ğŸ‘‰ Backend can talk to DB via service DNS name:

mysql-service

â¤ 4. Expose app to outside world
====================================
ğŸ‘‰ Some Services expose your app to external internet.

ğŸ§© Types of Services in Kubernetes
*************************************
1ï¸âƒ£ ClusterIP (Default)
=======================
â¤ Used for internal communication inside the cluster.

ğŸ‘‰ Not accessible from outside the cluster.
ğŸ‘‰ Good for backend â†’ database communication.

Example:
Frontend Pod â†’ ClusterIP Service â†’ Backend Pod

2ï¸âƒ£ NodePort
=============
â¤ Used to expose the application outside the cluster using a port on each worker node.

ğŸ‘‰ NodePort range: 30000â€“32767
ğŸ‘‰ Access via:

<node-ip>:<nodePort>

3ï¸âƒ£ LoadBalancer
=================
â¤ Used to expose services publicly on the internet.

ğŸ‘‰ Cloud providers (AWS, GCP, Azure) create a real load balancer for the Service.
ğŸ‘‰ Perfect for production.

4ï¸âƒ£ ExternalName
=================
â¤ Maps a Kubernetes Service â†’ external DNS name.

ğŸ‘‰ Used to connect internal apps to external resources.

Example:

externalName: google.com

5ï¸âƒ£ Headless Service
=====================
â¤ Used when you donâ€™t need load balancing.
â¤ Returns Pod IPs directly, not Service IP.

ğŸ‘‰ Used for:
--------------
â¤ Stateful apps (databases)
â¤ Pods needing direct communication

ğŸ§ª Real-World Example Use Cases
*********************************
â˜ï¸ ClusterIP
=============
â¤ Backend communicating with database
â¤ Microservices internal communication

ğŸŒ NodePort
==============
â¤ Testing apps from outside without cloud load balancer

ğŸš€ LoadBalancer
=================
â¤ Production apps exposed to internet

ğŸ§± Headless
============
â¤ Databases like:
â¤ Cassandra
â¤ MongoDB
â¤ StatefulSets

ğŸ“ Basic Service YAML Example
*******************************
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 8080

â¤ port â†’ Service port
â¤ targetPort â†’ Container port
â¤ selector â†’ Connects the service to matching Pods

ğŸ¯ In One Line
*****************
â¤ Service = stable IP + DNS + load balancing + internal/external connectivity for Pods.

#######################################################
ğŸ“„â˜¸ï¸ Kubernetes Manifest YAML â€” Complete Explanation
#######################################################
â¤ A Kubernetes Manifest YAML is the configuration file used to tell Kubernetes what you want to create or manage in the cluster.
â¤ Here is the perfect note-friendly explanation for you ğŸ‘‡

ğŸ§¾ What is a Kubernetes Manifest YAML?
****************************************
â¤ A Manifest YAML is a file written in YAML format that describes the desired state of Kubernetes resources like:
â¤ Pod
â¤ Deployment
â¤ Service
â¤ ConfigMap
â¤ Secret
â¤ Ingress
â¤ Namespace
â¤ PersistentVolume
â¤ And many moreâ€¦

â¤ YAML file tells Kubernetes what to create, configure, or update.

ğŸ‘‰ You donâ€™t manually create Pods/Services â€” you write YAML, and Kubernetes does the rest.

â­ Why Do We Use Manifest Files?
**********************************
â¤ 1. Declarative approach
==========================
ğŸ‘‰ You describe WHAT you want, not HOW to do it.

â¤ 2. Repeatability
====================
ğŸ‘‰ Same YAML can be used to deploy the app anywhere:
â¤ Dev
â¤ Staging
â¤ Production

â¤ 3. Version control
=======================
ğŸ‘‰ YAML files can be stored in Git for CI/CD pipelines.

â¤ 4. Easier to maintain
==========================
ğŸ‘‰ Teams can review YAML instead of commands.

ğŸ§± Basic Structure of a Kubernetes YAML Manifest
**************************************************
â¤ A manifest usually has 4 main sections:

1ï¸âƒ£ apiVersion
===============
â¤ Defines which version of Kubernetes API to use.
Examples:

apiVersion: v1
apiVersion: apps/v1

2ï¸âƒ£ kind
=========
â¤ Defines the type of Kubernetes object:

Pod
Deployment
Service
ConfigMap

3ï¸âƒ£ metadata
=============
â¤ Contains information like:
â¤ name
â¤ labels
â¤ namespace

Example:

metadata:
  name: myapp

4ï¸âƒ£ spec (Specification)
=========================
â¤ MOST IMPORTANT part.
â¤ Defines the desired state of the object.
Examples:
â¤ Number of replicas
â¤ Container image
â¤ Ports
â¤ Volumes
â¤ Selector

ğŸ“ Example Kubernetes Deployment Manifest YAML
************************************************
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: nginx-container
        image: nginx:latest
        ports:
        - containerPort: 80

ğŸ“ Example Kubernetes Service Manifest YAML
**********************************************
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 80

ğŸ¯ In One Line
****************
â¤ A Kubernetes Manifest YAML is a declarative configuration file that tells Kubernetes what resources to create and how they should behave.

##########################################################
â˜¸ï¸ Kubernetes Service Manifest YAML â€“ Clean Explanation
##########################################################
ğŸ“„ K8s Service Manifest YAML (NodePort Example)
---
apiVersion: v1
kind: Service
metadata:
  name: testpod-service
spec:
  type: NodePort
  selector:
    app: demoapp             
  ports:
    - port: 80               
      targetPort: 9090       
      nodePort: 30080        

ğŸ“˜ Explanation (Field-by-Field)
*********************************
â¤ name: testpod-service
===========================
ğŸ‘‰ Name of the service object.

â¤ type: NodePort
===================
ğŸ‘‰ Exposes the application outside the cluster using <NodeIP>:<NodePort>.

â¤ selector â†’ app: demoapp
===========================
ğŸ‘‰ Connects the service to Pods having this label.
ğŸ‘‰ This MUST match the Podâ€™s metadata.labels.

â¤ port: 80
=============
ğŸ‘‰ Internal service port (inside cluster).
ğŸ‘‰ Common for HTTP traffic.

â¤ targetPort: 9090
=====================
ğŸ‘‰ Port your container actually listens on inside the Pod.

â¤ nodePort: 30080
===================
ğŸ‘‰ External port open on every Kubernetes node.
ğŸ‘‰ Access application using:

http://<NodeIP>:30080/

ğŸ’» Useful kubectl Commands
****************************
â¤ Check Services
kubectl get svc

â¤ Create Service from YAML
kubectl apply -f testpod-service.yml

â¤ Verify Service
kubectl get svc

â¤ Open Service in Browser (Minikube Only)
minikube service testpod-service

ğŸŒ Test from Browser or Terminal
*********************************
â¤ Get Minikube IP
minikube ip

â¤ Test From Host Machine (Same Network)
curl http://<Minikube-IP>:30080/

Example:
curl http://192.168.49.2:30080/

ğŸ§  curl Command Explanation
******************************
#########################################################################################
| Part                                           | Meaning                              |
| ---------------------------------------------- | ------------------------------------ |
| **curl**                                       | CLI tool to make HTTP requests       |
| **[http://192.168.49.2](http://192.168.49.2)** | Minikube VM IP (cluster entry point) |
| **:30080**                                     | NodePort exposed by the service      |
| **/**                                          | Hits root ("/") endpoint of your app |
#########################################################################################

ğŸ—‘ï¸ Delete Pod / Service
=========================
â¤ Delete Pod
kubectl delete pod testpod

â¤ Delete Service
kubectl delete svc testpod-service

â¤ Recreate Resources
kubectl apply -f pod-01.yml
kubectl apply -f service-01.yml

ğŸ§¹ Clean Up Minikube
======================
â¤ Stop Minikube
minikube stop

â¤ Delete Minikube Cluster
minikube delete

â¤ Check Status
minikube status

ğŸ“Š View All Resources
========================
kubectl get all

ğŸ—‘ï¸ Delete All Resources in Namespace
======================================
kubectl delete all --all

##########################################
ğŸ§© ğŸ—‚ï¸ What Are Namespaces in Kubernetes?
##########################################
â¤ A Namespace is a logical partition inside a Kubernetes cluster used to organize and isolate resources.
â¤ Think of a namespace as a folder inside your cluster where you keep specific resources (Pods, Services, Deployments, etc.).

ğŸ¯ Why Do We Use Namespaces?
******************************
â¤ Isolation of resources
==========================
ğŸ‘‰ Resources inside one namespace cannot access resources in another namespace unless allowed.

â¤ Avoid name conflicts
=========================
ğŸ‘‰ You can have two Deployments named app but in different namespaces.

â¤ Access control (RBAC)
=========================
ğŸ‘‰ You can give team A access to namespace team-a but restrict access to prod.

â¤ Resource quotas
===================
ğŸ‘‰ You can limit CPU, memory, number of pods per namespace.

â¤ Organize environments
=========================
ğŸ‘‰ Example namespaces:
dev
test
stage
prod

ğŸ§± How Namespaces Work Internally
***********************************
â¤ When you create a resource without specifying a namespace â†’ It goes to default namespace.

â¤ Some resources are not namespaced (cluster-wide), such as:
ğŸ‘‰ Nodes
ğŸ‘‰ PersistentVolumes
ğŸ‘‰ StorageClasses

ğŸ“Œ Default Namespaces in Kubernetes
*************************************
Kubernetes comes with 4 namespaces by default:

â¤ default
============
ğŸ‘‰ Where your workloads go if you don't specify a namespace.

â¤ kube-system
================
ğŸ‘‰ Contains internal components (scheduler, controller manager, DNS, etc.).

â¤ kube-public
================
ğŸ‘‰ Publicly readable objects (rarely used).

â¤ kube-node-lease
===================
ğŸ‘‰ Stores node heartbeat objects for monitoring node availability.

ğŸ› ï¸ Common Namespace Commands
*****************************
â¤ List namespaces
-------------------
kubectl get ns

â¤ Create a namespace
----------------------
kubectl create namespace dev

â¤ Delete a namespace
----------------------
kubectl delete namespace dev

â¤ See resources inside a namespace
------------------------------------
kubectl get pods -n dev

â¤ Apply manifest to a namespace
---------------------------------
kubectl apply -f app.yaml -n dev

â¤ Set a default namespace for kubectl
---------------------------------------
kubectl config set-context --current --namespace=dev

ğŸ§  Real-Life Analogy
**********************
ğŸ‘‰ Imagine your cluster is a big office building, and namespaces are different departments like HR, Sales, Engineering.
Each department has:
â¤ Its own space
â¤ Its own employees/resources
â¤ Access rules
â¤ Its own budget (resource quota)

They all exist inside the same building but do not interfere with each other.

########################################
ğŸ“¦ Kubernetes Resources (K8s Resources)
########################################
â¤ Kubernetes resources are the building blocks you create and manage inside a cluster.
â¤ Anything you deploy, run, or configure in Kubernetes is treated as a resource.

ğŸ§© Types of Kubernetes Resources
**********************************
1ï¸âƒ£ ğŸ§± Core Resources (Fundamental Resources)
===============================================
These are the most commonly used resources.

â¤ Pod
--------
ğŸ‘‰ Smallest deployable unit in Kubernetes
ğŸ‘‰ Runs one or more containers

â¤ ReplicaSet
--------------
ğŸ‘‰ Ensures a fixed number of Pods are always running
ğŸ‘‰ Automatically replaces crashed Pods

â¤ Deployment
---------------
ğŸ‘‰ Most used resource for app deployment
ğŸ‘‰ Provides:
â¤ Rolling updates
â¤ Rollbacks
â¤ Version control
â¤ Auto-scaling compatibility

â¤ Service
-----------
ğŸ‘‰ Provides network access to Pods
ğŸ‘‰ Types: ClusterIP, NodePort, LoadBalancer

â¤ Namespace
--------------
ğŸ‘‰ Logical grouping of resources
ğŸ‘‰ Used for multi-team isolation, RBAC, different environments (dev/prod)

2ï¸âƒ£ â˜ï¸ Networking Resources
============================
â¤ Ingress
-----------
ğŸ‘‰ Exposes HTTP/HTTPS apps using a URL or domain
ğŸ‘‰ Works like a reverse proxy + load balancer

â¤ Endpoints / EndpointSlice
------------------------------
ğŸ‘‰ Store Pod IPs behind a Service
ğŸ‘‰ Used for routing requests

3ï¸âƒ£ ğŸ—‚ï¸ Storage Resources
===========================
â¤ PersistentVolume (PV)
--------------------------
ğŸ‘‰ Actual storage in cluster
ğŸ‘‰ Can come from AWS EBS, NFS, GCP, Minikube, etc.

â¤ PersistentVolumeClaim (PVC)
--------------------------------
ğŸ‘‰ Request for PV storage
ğŸ‘‰ Your application requests storage via PVC

â¤ ConfigMap
--------------
ğŸ‘‰ Stores non-sensitive configuration (URLs, ENV variables)

â¤ Secret
-----------
ğŸ‘‰ Stores sensitive data (passwords, tokens, API keys)
ğŸ‘‰ Base64 encoded

4ï¸âƒ£ âš™ï¸ Workload Resources
==========================
â¤ StatefulSet
--------------
ğŸ‘‰ Deploys apps that need stable identity + persistent storage
ğŸ‘‰ Used for databases: MySQL, MongoDB, Cassandra

â¤ DaemonSet
-------------
ğŸ‘‰ Runs one Pod per node
ğŸ‘‰ Used for log collectors, monitoring agents, kube-proxy

â¤ Job
--------
ğŸ‘‰ Runs once, completes task, stops
ğŸ‘‰ Example: data backup job

â¤ CronJob
-----------
ğŸ‘‰ Runs jobs on a schedule
ğŸ‘‰ Like Linux CRON (e.g., run every night)

5ï¸âƒ£ ğŸ›¡ï¸ Security & Access Resources
==================================
â¤ ServiceAccount
-------------------
ğŸ‘‰ Used by Pods to access API server
ğŸ‘‰ Provides identity for workloads

â¤ Role & RoleBinding
----------------------
ğŸ‘‰ Namespace-level permissions

â¤ ClusterRole & ClusterRoleBinding
-----------------------------------
ğŸ‘‰ Cluster-level permissions
ğŸ‘‰ Admin-level access

6ï¸âƒ£ ğŸ“Š Auto-Scaling Resources
==============================
â¤ Horizontal Pod Autoscaler (HPA)
-------------------------------------
ğŸ‘‰ Auto-increases or decreases Pod replicas based on CPU/Mem

â¤ Vertical Pod Autoscaler (VPA)
---------------------------------
ğŸ‘‰ Auto-adjusts container CPU/memory requests/limits

â¤ Cluster Autoscaler
----------------------
ğŸ‘‰ Adds/removes worker nodes automatically

7ï¸âƒ£ ğŸ”§ System Resources
==========================
â¤ Node
--------
ğŸ‘‰ Worker machine (VM, physical, or cloud instance)

â¤ Resource Quota
-------------------
ğŸ‘‰ Limits how much CPU, memory, storage a namespace can use

â¤ LimitRange
---------------
ğŸ‘‰ Defines min/max resources for each Pod/container

ğŸ¯ Summary Table
*****************
################################################################
| Category   | Resources                                       |
| ---------- | ----------------------------------------------- |
| Core       | Pod, ReplicaSet, Deployment, Service, Namespace |
| Networking | Ingress, EndpointSlice                          |
| Storage    | PV, PVC, ConfigMap, Secret                      |
| Workload   | StatefulSet, DaemonSet, Job, CronJob            |
| Security   | ServiceAccount, Role, RBAC                      |
| Scaling    | HPA, VPA, Cluster Autoscaler                    |
| System     | Node, ResourceQuota, LimitRange                 |
################################################################

##########################################
ğŸ§© ğŸ¤– What is a Replication Controller?
##########################################
â¤ A Replication Controller (RC) is an older Kubernetes resource that ensures a specified number of Pod replicas are always running.
â¤ If a Pod crashes or is deleted â†’ RC will create a new Pod automatically.
â¤ If extra Pods are running â†’ RC will delete the extra Pods to match the desired count.

ğŸ“Œ RC maintains Pod count, not Pod version.

ğŸ¯ ğŸ’¡ Why was Replication Controller used?
*********************************************
â¤ To maintain high availability
â¤ To auto-restart failed Pods
â¤ To scale applications horizontally
â¤ To ensure a stable running environment

ğŸ›‘ âš ï¸ Replication Controller Deprecated
******************************************
â¤ Replication Controller is obsolete.
â¤ Modern Kubernetes uses ReplicaSet instead.
â¤ Even ReplicaSet is rarely used directly â†’ handled automatically by Deployment.

ğŸ“Œ Real-world usage today: 0%
All companies use Deployment.

ğŸ” Replication Controller vs ReplicaSet
******************************************
#################################################################################
| Feature         | Replication Controller (RC) | ReplicaSet (RS)               |
| --------------- | --------------------------- | ----------------------------- |
| Selector        | Only equality-based         | Supports set-based selectors  |
| Usage Today     | Deprecated                  | Used internally by Deployment |
| Rolling Updates | âŒ No                        | âŒ No (Deployment does this)|
| Modern Use      | Not used                    | Not used directly             |
#################################################################################

ğŸ”§ Replication Controller YAML Example
***************************************
apiVersion: v1
kind: ReplicationController
metadata:
  name: nginx-rc
spec:
  replicas: 3
  selector:
    app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: nginx
        image: nginx:latest

âš™ï¸ How RC Works (Simple Explanation)
*************************************
â¤ You specify:
-----------------
replicas: 3

label selector: app=myapp

â¤ RC continuously checks:
----------------------------
ğŸ‘‰ If only 2 Pods running â†’ create 1 more
ğŸ‘‰ If 4 Pods running â†’ delete 1
ğŸ‘‰ If Pod crashes â†’ recreate
ğŸ‘‰ If Pod is manually deleted â†’ recreate

ğŸ“Œ RC keeps quantity stable, not Pod version.

ğŸ§  Key Points for Notes
**************************
â¤ RC ensures a fixed number of Pods
â¤ Auto-healing: recreates failed Pods
â¤ Obsolete â†’ replaced by ReplicaSet
â¤ Deployment manages ReplicaSets
â¤ RC has limited label selectors

###################################
ğŸ¤– ReplicaSet (RS) in Kubernetes
###################################
ğŸ§© What is a ReplicaSet?
***************************
â¤ A ReplicaSet (RS) is a Kubernetes resource that ensures a specific number of identical Pods are running at all times.
â¤ It provides self-healing and horizontal scaling for Pods.

ğŸŒŸ Key Features of ReplicaSet
******************************
â¤ 1. Self-Healing
===================
ğŸ‘‰ If a Pod crashes or is manually deleted, RS creates a new Pod automatically.

â¤ 2. Scaling
==============
ğŸ‘‰ Easy to scale Pods:

kubectl scale rs webapp --replicas=5

â¤ 3. Label Selector Based Management
======================================
ğŸ‘‰ RS only manages Pods matching its selector.
ğŸ‘‰ Other Pods are ignored even if running in the cluster.

â¤ 4. Set-Based Selectors
=========================
ğŸ‘‰ Supports:
In
NotIn
Exists

(This is one major improvement over ReplicationController.)

ğŸ”¥ Important Concept
***********************
"ReplicaSet maintains Pod count, not Pod version."
For rolling updates â†’ Deployment is used.

ğŸ§ª Understanding With Example
*******************************
ğŸŸ¦ Pod 1 â€” Label: app: myapp
------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
    - name: myappcontainer
      image: nginx
      ports:
        - containerPort: 80

ğŸŸª Pod 2 â€” Label: app: dempapp
--------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: dempapp-pod
  labels:
    app: dempapp
spec:
  containers:
    - name: dempappcontainer
      image: nginx
      ports:
        - containerPort: 80

ğŸŸ¥ ReplicaSet Managing BOTH Pods

(Because the selector uses matchExpressions)

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: rs-webapp
spec:
  replicas: 2
  selector:
    matchExpressions:
      - key: app
        operator: In
        values:
          - dempapp
          - myapp
  template:
    metadata:
      labels:
        app: dempapp
    spec:
      containers:
        - name: webappcontainer
          image: nginx
          ports:
            - containerPort: 80

ğŸ“Œ Pods created by the ReplicaSet will always get the label:

app: dempapp

ğŸ“Œ But existing Pods with labels myapp or dempapp will also be counted by the RS due to the selector.

ğŸ§ª Practical ReplicaSet + Service YAML
---------------------------------------
replica-set.yml

---
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: webapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: dempapp         # Must match pod template labels
  template:
    metadata:
      labels:
        app: dempapp
    spec:
      containers:
        - name: webappcontainer
          image: psait/pankajsiracademy:latest
          ports:
            - containerPort: 9090

---
apiVersion: v1
kind: Service
metadata:
  name: webappservice
spec:
  type: NodePort
  selector:
    app: dempapp           # Must match pod labels
  ports:
    - port: 80
      targetPort: 9090
      nodePort: 30095

ğŸ§ª Commands for Testing
*************************
â¤ Create resources
kubectl apply -f replica-set.yml

â¤ Check ReplicaSet
kubectl get rs

â¤ Check Pods created by RS
kubectl get pods

â¤ Expose service (Minikube)
minikube service webappservice

ğŸ¯ Summary (Best for Notes)
*****************************
â¤ ReplicaSet ensures desired Pod count
â¤ Supports set-based selectors
â¤ Provides self-healing & scaling
â¤ Does NOT support rolling updates
â¤ Used internally by Deployment
â¤ Companies use Deployment â†’ not ReplicaSet directly

#####################################################
ğŸ”„ ReplicationController vs ReplicaSet (Kubernetes)
#####################################################
ğŸ§© ğŸ¤– What is ReplicationController (RC)?
********************************************
â¤ Old/legacy Kubernetes workload
â¤ Ensures a fixed number of Pods are running
â¤ Uses only equality-based selectors
â¤ No rolling updates
â¤ Practically not used anymore

ğŸ” ğŸ¤– What is ReplicaSet (RS)?
*********************************
â¤ Modern and advanced version of RC
â¤ Ensures a fixed number of Pods
â¤ Supports set-based selectors
â¤ Forms the core of Deployments (used internally)
â¤ Not used directly, but still active

ğŸ†š Key Differences: ReplicaSet vs ReplicationController
*********************************************************
###################################################################################################################
| Feature              | ReplicationController (RC)          | ReplicaSet (RS)                                    |
| -------------------- | ----------------------------------- | -------------------------------------------------- |
| **Selector Support** | Only *equality-based* (`app=myapp`) | *Set-based* (`In`, `NotIn`, `Exists`)              |
| **Rolling Updates**  | âŒ Not Supported                    | âŒ Not directly â†’ Done via Deployment             |
| **Used By**          | Deprecated â†’ Not used               | Used internally by Deployment                      |
| **Modern Usage**     | Almost 0%                           | Indirectly used (Deployment creates ReplicaSets)   |
| **Functionality**    | Maintains number of Pods            | More powerful Pod selection + auto-scaling support |
| **YAML**             | apiVersion: v1                      | apiVersion: apps/v1                                |
| **Replacement**      | Replaced by ReplicaSet              | Used but not directly deployed in real world       |
###################################################################################################################

ğŸ¯ Most Important Practical Difference
****************************************
â¤ ReplicationController selector
===================================
ğŸ‘‰ Only equality match:

selector:
  app: myapp

â¤ ReplicaSet selector
========================
ğŸ‘‰ Allows set-based selection:

matchExpressions:
  - key: app
    operator: In
    values:
      - app1
      - app2

This allows RS to manage multiple labeled pods, something RC cannot do.

âš™ï¸ Why ReplicaSet Replaced ReplicationController
*************************************************
â¤ 1. More powerful label selectors
â¤ 2. Better integration with Deployment
â¤ 3. More flexible pod grouping
â¤ 4. RC became redundant and outdated

ğŸ§  Best Summary (Add to Notes)
********************************
â¤ RC = Old, simple, only equality selectors, obsolete
â¤ RS = Improved RC + supports set-based selectors
â¤ Deployment = Manages RS and provides rolling updates
â¤ Real world â†’ You only create Deployments, not RC or RS

########################################
ğŸš€ What is a Deployment in Kubernetes?
########################################
â¤ A Deployment is a higher-level controller in Kubernetes that manages ReplicaSets and Pods for you.
â¤ Think of it as:
A smart manager who ensures your app is always running, updated safely, and scalable.

â¤ It is the most commonly used K8s object to run applications.

ğŸ¯ Why do we use Deployment?
******************************
â¤ Because a Deployment gives you powerful features like:
âœ” Auto-create & manage ReplicaSets
-> It automatically handles creating & updating ReplicaSets.

âœ” Rolling updates
-> Update your app without downtime.

âœ” Rollbacks
-> Go back to the previous version if something breaks.

âœ” Scaling
-> Increase or decrease replicas easily.

âœ” Self-healing
-> If Pods/ReplicaSets fail, Deployment replaces them.

ğŸ§© How Deployment Works (in simple terms)
********************************************
â¤ You create a Deployment YAML (telling: image, replicas, labels).
â¤ Deployment creates a ReplicaSet.
â¤ ReplicaSet creates Pods.
â¤ If you update the Deployment:
-> A new ReplicaSet is created automatically.
-> Old Pods are replaced gradually â†’ rolling update.

â¤ If update fails:
-> Deployment switches back to old ReplicaSet â†’ rollback.

ğŸ”§ Simple Deployment YAML
---------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment

spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp

  template:
    metadata:
      labels:
        app: myapp

    spec:
      containers:
        - name: myapp
          image: nginx:latest

ğŸ§  Easy Analogy
*****************
â¤ Think of Deployment as the project manager:
â¤ ReplicaSet = team leader
â¤ Pods = workers
â¤ You instruct the manager (Deployment), not the team leader.

ğŸŸ¦ In One Line
******************
â¤ A Deployment is the recommended way to run, update, scale, and manage your application Pods in Kubernetes.